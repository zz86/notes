
![[Pasted image 20220906221946.png|700]]

## 机器学习项目开发步骤
![[Pasted image 20220907091441.png|600]]

## 回归算法
![[Pasted image 20220907102227.png|700]]

在线性回归算法中，机器是通过梯度下降，逐步减少数据集拟合过程中的损失，让线性函数对特征到标签的模拟越来越贴切。

在决策树模型中，算法是通过根据特征值选择 划分点来确定输出值的；

在随机森林算法中，机器则是生成多棵决策树，并通过 Bagging 的方法得到最终的预测模型。

## 分类算法
![[Pasted image 20220907223910.png]]

## 四个提升机器学习模型准确度的法宝
1. 特征工程：目标是提高数据特征与模型的匹配度，我们总结了特征选择、特征变换和特征构建三个思路来帮助你解决具体问题。

2. 防过拟合：过拟合就是模型针对训练集，拟合程度过高，失去了在新数据集上泛化的能力。我们的模型要在拟合和泛化之间保持一个平衡。

3. 交叉验证：交叉验证可以帮我们利用好有限的数据集。你要注意，我们说的过拟合也有可能不是模型导致的，而可能是因为数据集划分不合理造成的，这在比较小的数据集上 尤为明显。所以，交叉验证所得到的多次评估结果，能够避免某一次数据集划分不合理所带来的偏差。

4. 参数调优：每一种算法都有属于自己的一系列可调超参数（外部参数），你要尽力找到对于当前数据集而言最好的一套参数。

![[Pasted image 20220907210003.png|700]]

## 三个深度学习神经网络性能优化的方法

第一个方法是针对图形数据做增广，也就是把有限的数据个数变多。其实不只是 CNN 网络，对于其他神经网络 模型，乃至神经网络模型之外的模型来说，数据的数量都是多多益善。数据的量越大，模 型出现过拟合的风险就越小。

第二个方法是在网络模型中增加一些 Dropout 层，这种类型的神经网络层，通过阻止各个 神经元之间的共同作用，阻止它们形成固定的特征提取模式来提高神经网络的泛化能力。

第三个方法是尝试使用不同类型的神经网络优化器，来克服网络训练时落入局部最低点的 问题。其中，最常用的神经网络优化器是 Adam，但具体到每一个数据集来说，可能还有 更适合自己的优化器，因此，我建议你在实际项目中最好还是多试试不同的优化器。就目 前而言，RMSprop 和 Adam 都是常用的优化器，而 Adam 更是多种优化思路的集大成 者，一般情况下是优化器的首选项。
![[Pasted image 20220907221507.png|700]]
