
## linux如何表示一个页
linux使用分页模型来管理内存。首先是把物理内存空间分成 4KB 大小页，这页表示从地址 x 开始到 x+0xFFF 这一段的物理内存空间，x 必须是 0x1000 对齐的。这一段 x+0xFFF 的 内存空间，称为内存页。
![[Pasted image 20220901211341.png|500]]




## 虚拟地址
每个应用程序的虚拟地址空间都是相同且独立的。

那么这个地址是由谁产生的呢？ 答案是链接器

其实我们开发软件经过编译步骤后，就需要链接成可执行文件才可以运行，而链接器的主要工作就是把多个代码模块组装在一起，并解决模块之间的引用，即处 理程序代码间的地址引用，形成程序运行的静态内存空间视图。 

只不过这个地址是虚拟而统一的，而根据操作系统的不同，这个虚拟地址空间的定义也许 不同，应用软件开发人员无需关心，由开发工具链给自动处理了。由于这虚拟地址是独立 且统一的，所以各个公司开发的各个应用完全不用担心自己的内存空间被占用和改写。

虚拟地址就是逻辑上的一个数值，而虚拟地址空间就是一堆数值的集合。通常情况下，32 位的处理器有 0～0xFFFFFFFF 的虚拟地址空间，也就是4G，而 64 位的虚拟地址空间则更大，有 0～ 0xFFFFFFFFFFFFFFFF 的虚拟地址空间，也就是128T。

#### x86 CPU 如何划分虚拟地址空间
由于 x86 CPU 支持虚拟地址空间时，要么开启保护模式，要么开启长模式。

保护模式下是 32 位的，有 0～0xFFFFFFFF 个地址，可以使用完整的 4GB 虚拟地址空间。

在保护模式下，对这 4GB 的虚拟地址空间没有进行任何划分，而长模式下是 64 位的虚拟 地址空间有 0～0xFFFFFFFFFFFFFFFF 个地址，这个地址空间非常巨大，硬件工程师根据需 求设计，把它分成了 3 段，如下图所示。
![[Pasted image 20220901213127.png|700]]
长模式下，CPU 目前只实现了 48 位地址空间，但寄存器却是 64 位的，CPU 自己用地址 数据的第 47 位的值扩展到最高 16 位，所以 64 位地址数据的最高 16 位，要么是全 0， 要么全 1，这就是我们在上图看到的情形。


![[Pasted image 20220909154201.png|800]]


## VFS
在 Linux 中，支持 EXT、XFS、JFS、BTRFS、FAT、NTFS 等多达十几种不同的文件系 统，但不管在什么储存设备上使用什么文件系统，也不管访问什么文件，都可以统一地使 用一套 open(), read()、write()、close() 这样的接口。 

这些接口看上去都很简单，但要基于不同的存储设备设计，还要适应不同的文件系统，这 并不容易。这就得靠优秀的 VFS 了，它提供了一个抽象层，让不同的文件系统表现出一致 的行为。
![[Pasted image 20220905100444.png|600]]
上图中 Linux 的 VFS 层就是应用和许多文件系统之间的抽象层。VFS 向上对应用提供 了操作文件的标准接口，向下规范了一个文件系统要接入 VFS 必需要实现的机制。

## Page Cache
![[Pasted image 20220905151517.png|600]]
1. Page Cache 是属于内核的，不属于用户。 
2. Page Cache 对应用提升 I/O 效率而言是一个投入产出比较高的方案，所以它的存在还 是有必要的。

### Page Cache 是如何“诞生”的？
![[Pasted image 20220905152142.png|900]]
Page Cache 的产生有两种不同的方式：
**Buffered I/O（标准 I/O）：**
标准 I/O 是写的 (write(2)) 用户缓冲区 (Userpace Page 对应的内存)，然后再将用户缓冲区里的数据拷贝到内核缓冲区 (Pagecache Page 对应的内存)；如果是读的 (read(2)) 话则是先从内核缓冲区拷贝到用户缓冲区，再从用户缓冲区读数据，也就是 buffer 和文件内容 不存在任何映射关系。
![[Pasted image 20220905152650.png|800]]
这个过程大致可以描述为：首先往用户缓冲区 buffer(这是 Userspace Page) 写入数据， 然后 buffer 中的数据拷贝到内核缓冲区（这是 Pagecache Page），如果内核缓冲区中还 没有这个 Page，就会发生 Page Fault 会去分配一个 Page，拷贝结束后该 Pagecache Page 是一个 Dirty Page（脏页），然后该 Dirty Page 中的内容会同步到磁盘，同步到磁 盘后，该 Pagecache Page 变为 Clean Page 并且继续存在系统中。 

我建议你可以将 Alloc Page 理解为 Page Cache 的“诞生”，将 Dirty Page 理解为 Page Cache 的婴幼儿时期（最容易生病的时期），将 Clean Page 理解为 Page Cache 的成年时期（在这个时期就很少会生病了）。

但是请注意，并不是所有人都有童年的，比如孙悟空，一出生就是成人了，Page Cache 也一样，如果是读文件产生的 Page Cache，它的内容跟磁盘内容是一致的，所以它一开 始是 Clean Page，除非改写了里面的内容才会变成 Dirty Page（返老还童）。

**Memory-Mapped I/O（存储映射 I/O）：**
对于存储映射 I/O 而言，则是直接将 Pagecache Page 给映射到用户地址空间，用户直接读写 Pagecache Page 中内容。

显然，存储映射 I/O 要比标准 I/O 效率高一些，毕竟少了“用户空间到内核空间互相拷 贝”的过程。这也是很多应用开发者发现，为什么使用内存映射 I/O 比标准 I/O 方式性能 要好一些的主要原因。

### Page Cache 是如何“死亡”的？
你可以把 Page Cache 的回收行为 (Page Reclaim) 理解为 Page Cache 的“自然死 亡”。

free 命令中的 buff/cache 中的这些就是“活着”的 Page Cache，那它们什么时候会“死 亡”（被回收）呢？我们来看一张图：
![[Pasted image 20220905153331.png]]
你可以看到，应用在申请内存的时候，即使没有 free 内存，只要还有足够可回收的 Page Cache，就可以通过回收 Page Cache 的方式来申请到内存，回收的方式主要是两种：**直接回收和后台回收**

**直接内存**回收是在进程申请内存的过程中同步进行的回收，而这个回收过程可能会消 耗很多时间，进而导致进程的后续行为都被迫等待，这样就会造成很长时间的延迟，以及 系统的 CPU 利用率会升高，最终引起 load 飙高。
![[Pasted image 20220905153645.png|600]]
在开始内存回收后，首先进行后台异步回收（上图中蓝色标记的地 方），这不会引起进程的延迟；如果后台异步回收跟不上进行内存申请的速度，就会开始同步阻塞回收，导致延迟（上图中红色和粉色标记的地方，这就是引起 load 高的地址）。

针对直接内存回收引起 load 飙高或者业务 RT 抖动的问题，一个解决方案就是及早地触发后台回收来避免应用程序进行直接内存回收。

直接回收过程中，如果存在较多脏页就可能涉及在回收过程中进行回写，这可能会造成非常大的延迟，而且因为这个过程本身是阻塞式的，所以又可能进一步导致系统中处于 D 状态的进程数增多，最终的表现就是系统的 load 值很高。

### 如何避免 Page Cache 里相对比较重要的数据被回收掉：
避免 Page Cache 里相对比较重要的数据被回收掉的思路也是有两种：
**从应用代码层面来优化；** 
从应用程序代码层面来解决是相对比较彻底的方案，因为应用更清楚哪些 Page Cache 是 重要的，哪些是不重要的，所以就可以明确地来对读写文件过程中产生的 Page Cache 区 别对待。比如说，对于重要的数据，可以通过 mlock(2) 来保护它，防止被回收以及被 drop；对于不重要的数据（比如日志），那可以通过 madvise(2) 告诉内核来立即释放这 些 Page Cache。

**从系统层面来调整。**
在有些情况下，对应用程序而言，修改源码是件比较麻烦的事，如果可以不修改源码来达 到目的那就最好不过了。Linux 内核同样实现了这种不改应用程序的源码而从系统层面调整 来保护重要数据的机制，这个机制就是 **memory cgroup protection**
它大致的思路是，将需要保护的应用程序使用 memory cgroup 来保护起来，这样该应用 程序读写文件过程中所产生的 Page Cache 就会被保护起来不被回收或者最后被回收。 memory cgroup protection 大致的原理如下图所示：
![[Pasted image 20220905162909.png|600]]
如上图所示，memory cgroup 提供了几个内存水位控制线 memory.{min, low, high, max} 。
**memory.max**
这是指 memory cgroup 内的进程最多能够分配的内存，如果不设置的话，就默认不做 内存大小的限制。
**memory.high**
如果设置了这一项，当 memory cgroup 内进程的内存使用量超过了该值后就会立即被回收掉，所以这一项的目的是为了尽快的回收掉不活跃的 Page Cache。
**memory.low**
这一项是用来保护重要数据的，当 memory cgroup 内进程的内存使用量低于了该值后，在内存紧张触发回收后就会先去回收不属于该 memory cgroup 的 Page Cache， 等到其他的 Page Cache 都被回收掉后再来回收这些 Page Cache。
**memory.min**
这一项同样是用来保护重要数据的，只不过与 memoy.low 有所不同的是，当 memory cgroup 内进程的内存使用量低于该值后，即使其他不在该 memory cgroup 内的 Page Cache 都被回收完了也不会去回收这些 Page Cache，可以理解为这是用来保护 最高优先级的数据的。

那么，如果你想要保护你的 Page Cache 不被回收，你就可以考虑将你的业务进程放在一 个 memory cgroup 中，然后设置 memory.{min,low} 来进行保护；与之相反，如果你 想要尽快释放你的 Page Cache，那你可以考虑设置 memory.high 来及时的释放掉不活 跃的 Page Cache。
