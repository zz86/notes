
## 操作系统启动过程
首先，启动 BIOS。这是一个特别小的小系统，只能干特别小的一件事情。其实就是读取硬盘的 MBR 启动扇区，将 GRUB 启动起来；然后将权力交给 GRUB，GRUB 加载内核、加载作为根文件系统的 initramfs 文件；然后将权力交给内核；最后内核启动，初始化整个操作系统。

在机器加电后，BIOS 会进行自检，然后由 BIOS 加载引导设备中引导扇区。在安装有 Linux 操作系统的情况下，在引导扇区里，通常是安装的 GRUB 的一小段程序（安装 windows 的情况则不同）。最后，GRUB 会加载 Linux 的内核映像 vmlinuz，如下图所 示。
![[Pasted image 20220901204741.png|500]]
上图中的引导设备通常是机器中的硬盘，但也可以是 U 盘或者光盘甚至是软盘。BIOS 会 自动读取保存在 CMOS 中的引导设备信息。

![[Pasted image 20220901210519.png]]

## 从BIOS到GRUB
硬件工程师设计 CPU 时， 硬性地规定在加电的瞬间，强制将 CS 寄存器的值设置为 0XF000，IP 寄存器的值设置为 0XFFF0。

这样一来，CS:IP 就指向了 0XFFFF0 这个物理地址。在这个物理地址上连接了主板上的一 块小的 ROM 芯片。这种芯片的访问机制和寻址方式和内存一样，只是它在断电时不会丢 失数据，在常规下也不能往这里写入数据，它是一种只读内存，BIOS 程序就被固化在该 ROM 芯片里。

现在，CS:IP 指向了 0XFFFF0 这个位置，正是 BIOS 程序的入口地址。这意味着 BIOS 正 式开始启动。

BIOS 一开始会初始化 CPU，接着检查并初始化内存，然后将自己的一部分复制到内存， 最后跳转到内存中运行。BIOS 的下一步就是枚举本地设备进行初始化，并进行相关的检 查，检查硬件是否损坏，这期间 BIOS 会调用其它设备上的固件程序，如显卡、网卡等设 备上的固件程序。

当设备初始化和检查步骤完成之后，BIOS 会在内存中建立中断表和中断服务程序，这是启 动 Linux 至关重要的工作，因为 Linux 会用到它们。

具体是怎么操作的呢？BIOS 会从内存地址（0x00000）开始用 1KB 的内存空间 （0x00000~0x003FF）构建中断表，在紧接着中断表的位置，用 256KB 的内存空间构建 BIOS 数据区（0x00400~0x004FF），并在 0x0e05b 的地址加载了 8KB 大小的与中断表 对应的中断服务程序。

中断表中有 256 个条目，每个条目占用 4 个字节，其中两个字节是 CS 寄存器的值，两个 字节是 IP 寄存器的值。每个条目都指向一个具体的中断服务程序。

为了启动外部储存器中的程序，BIOS 会搜索可引导的设备，搜索的顺序是由 CMOS 中的 设置信息决定的（这也是我们平时讲的，所谓的在 BIOS 中设置的启动设备顺序）。一个是软驱，一个是光驱，一个是硬盘上，还可以是网络上的设备甚至是一个 usb 接口的 U 盘，都可以作为一个启动设备。

当然，Linux 通常是从硬盘中启动的。硬盘上的第 1 个扇区（每个扇区 512 字节空间）， 被称为 MBR（主启动记录），其中包含有基本的 GRUB 启动程序和分区表，安装 GRUB 时会自动写入到这个扇区，当 MBR 被 BIOS 装载到 0x7c00 地址开始的内存空间中后， BIOS 就会将控制权转交给了 MBR。在当前的情况下，其实是交给了 GRUB。

到这里，BIOS 到 GRUB 的过程结束。

## linux如何表示一个页
linux使用分页模型来管理内存。首先是把物理内存空间分成 4KB 大小页，这页表示从地址 x 开始到 x+0xFFF 这一段的物理内存空间，x 必须是 0x1000 对齐的。这一段 x+0xFFF 的 内存空间，称为内存页。
![[Pasted image 20220901211341.png|500]]


## CPU的工作模式
按照 CPU 功能升级迭代的顺序，CPU 的工作模式有实模式、保护模式、长模式

1. 实模式，早期 CPU 是为了支持单道程序运行而实现的，单道程序能掌控计算机所有的资 源，早期的软件规模不大，内存资源也很少，所以实模式极其简单，仅支持 16 位地址空 间，分段的内存模型，对指令不加限制地运行，对内存没有保护隔离作用。 
2. 保护模式，随着多道程序的出现，就需要操作系统了。内存需求量不断增加，所以 CPU 实现了保护模式以支持这些需求。 保护模式包含特权级，对指令及其访问的资源进行控制，对内存段与段之间的访问进行严 格检查，没有权限的绝不放行，对中断的响应也要进行严格的权限检查，扩展了 CPU 寄存 器位宽，使之能够寻址 32 位的内存地址空间和处理 32 位的数据，从而 CPU 的性能大大 提高。 
3. 长模式，又名 AMD64 模式，最早由 AMD 公司制定。由于软件对 CPU 性能需求永无 止境，所以长模式在保护模式的基础上，把寄存器扩展到 64 位同时增加了一些寄存器，使 CPU 具有了能处理 64 位数据和寻址 64 位的内存地址空间的能力。 长模式弱化段模式管理，只保留了权限级别的检查，忽略了段基址和段长度，而地址的检 查则交给了 MMU。

## 虚拟地址
每个应用程序的虚拟地址空间都是相同且独立的。

那么这个地址是由谁产生的呢？ 答案是链接器

其实我们开发软件经过编译步骤后，就需要链接成可执行文件才可以运行，而链接器的主要工作就是把多个代码模块组装在一起，并解决模块之间的引用，即处 理程序代码间的地址引用，形成程序运行的静态内存空间视图。 

只不过这个地址是虚拟而统一的，而根据操作系统的不同，这个虚拟地址空间的定义也许 不同，应用软件开发人员无需关心，由开发工具链给自动处理了。由于这虚拟地址是独立 且统一的，所以各个公司开发的各个应用完全不用担心自己的内存空间被占用和改写。

虚拟地址就是逻辑上的一个数值，而虚拟地址空间就是一堆数值的集合。通常情况下，32 位的处理器有 0～0xFFFFFFFF 的虚拟地址空间，也就是4G，而 64 位的虚拟地址空间则更大，有 0～ 0xFFFFFFFFFFFFFFFF 的虚拟地址空间，也就是128T。

#### x86 CPU 如何划分虚拟地址空间
由于 x86 CPU 支持虚拟地址空间时，要么开启保护模式，要么开启长模式。

保护模式下是 32 位的，有 0～0xFFFFFFFF 个地址，可以使用完整的 4GB 虚拟地址空间。

在保护模式下，对这 4GB 的虚拟地址空间没有进行任何划分，而长模式下是 64 位的虚拟 地址空间有 0～0xFFFFFFFFFFFFFFFF 个地址，这个地址空间非常巨大，硬件工程师根据需 求设计，把它分成了 3 段，如下图所示。
![[Pasted image 20220901213127.png|700]]
长模式下，CPU 目前只实现了 48 位地址空间，但寄存器却是 64 位的，CPU 自己用地址 数据的第 47 位的值扩展到最高 16 位，所以 64 位地址数据的最高 16 位，要么是全 0， 要么全 1，这就是我们在上图看到的情形。


## Ifconfig   vs   ip addr
- ifconfig  在 net-tools
- ip addr  在  iproute2

#### 进程
- 不共享任何状态
- 调度由操作系统完成
- 有独立的内存空间（上下文切换的时候需要保存栈、cpu寄存器、虚拟内存、以及打开的相关句柄等信息，开销大）
- 通讯主要通过信号传递的方式来实现（实现方式有多种，信号量、管道、事件等，通讯都需要过内核，效率低）
- 一个task_struct结构体的实例变量代表一个Linux进程
- Linux 进程调度支持多种调 度算法，有基于优先级的调度算法，有实时调度算法，有完全公平调度算法（CFQ）。

CFS调度器的核心就是让虚 拟时间最小的进程最先运行， 一旦进程运行虚拟时间就会增加，最后尽量保证所有进程的 虚拟时间相等，谁小了就要多运行，谁大了就要暂停运行。

为什么要用红黑树来组织调度实体（进程实体）？
这是因为要维护虚拟时间的顺序，又要从中频繁的删除和插入调度实体，这种情况下红黑树这种结构无疑是非常好。

#### 线程
- 共享变量（解决了通讯麻烦的问题，但是对于变量的访问需要加锁）
- 调度由操作系统完成（由于共享内存，上下文切换变得高效）
- 一个进程可以有多个线程，每个线程会共享父进程的资源（创建线程开销占用比进程小很多，可创建的数量也会很多）
- 通讯除了可使用进程间通讯的方式，还可以通过共享内存的方式进行通信（通过共享内存通信比通过内核要快很多）

#### 协程
- 调度完全由用户控制
- 一个线程（进程）可以有多个协程
- 每个线程（进程）循环按照指定的任务清单顺序完成不同的任务（当任务被堵塞时，执行下一个任务；当恢复时，再回来执行这个任务；任务间切换只需要保存任务的上下文，没有内核的开销，可以不加锁的访问全局变量）
- 协程需要保证是非堵塞的且没有相互依赖
- 协程基本上不能同步通讯，多采用异步的消息通讯，效率比较高

#### 总结
- 进程拥有自己独立的堆和栈，既不共享堆，亦不共享栈，进程由操作系统调度
- 线程拥有自己独立的栈和共享的堆，共享堆，不共享栈，线程亦由操作系统调度(标准线程是的)
- 协程和线程一样共享堆，不共享栈，协程由程序员在协程的代码里显示调度

## 信号
kill -l查看linux所有信号

如果我们按下键盘“Ctrl+C”，当前运行的进程就会收到一个信号 SIGINT 而退出；

如果我们的代码写得有问题，导致内存访问出错了，当前的进程就会收到另一个信号 SIGSEGV；

我们也可以通过命令 kill ，直接向一个进程发送一个信号，缺省情况下不指定信 号的类型，那么这个信号就是 SIGTERM。也可以指定信号类型，比如命令 “kill -9 ”, 这里的 9，就是编号为 9 的信号，SIGKILL 信号。

目前主流的 Linux 发行版，无论是 RedHat 系的还是 Debian 系的，都会把 /sbin/init 作 为符号链接指向 Systemd。Systemd 是目前最流行的 Linux init 进程，在它之前还有 SysVinit、UpStart 等 Linux init 进程，也就是1号进程。

![[Pasted image 20220826111104.png]]
对 于 SIGKILL 和 SIGSTOP 这个两个信号，进程是不能忽略的。这是因为它们的主要作用是 为 Linux kernel 和超级用户提供删除任意进程的特权。对于捕获，SIGKILL 和 SIGSTOP 这两个信号也同样例外，这两个信号不能有用户自己的 处理代码，只能执行系统的缺省行为。这两个特权信号，不能被忽略也不能被捕获。

对于大部分的信号而言，应用程序不需要注册自己的 handler，使用系统缺省定义行为就 可以了。对于每个信号，用户进程如果不注册一个自己的 handler，就会 有一个系统缺省的 handler，这个缺省的 handler 就叫作 SIG_DFL。

![[Pasted image 20220826111951.png]]

## 进程的状态
![[Pasted image 20220826160034.png]]
我们从这张图中可以看出来，在进程“活着”的时候就只有两个状态：运行态 （TASK_RUNNING）和睡眠态（TASK_INTERRUPTIBLE， TASK_UNINTERRUPTIBLE）。

运行态的意思是，无论进程是正在运行中（也就是获得了 CPU 资源），还是进程在 run queue 队列里随时可以运行，都处于这个状态。 我们想要查看进程是不是处于运行态，其实也很简单，比如使用 ps 命令，可以看到处于这 个状态的进程显示的是 R stat。

睡眠态是指，进程需要等待某个资源而进入的状态，要等待的资源可以是一个信号量 （Semaphore）, 或者是磁盘 I/O，这个状态的进程会被放入到 wait queue 队列里。

这个睡眠态具体还包括两个子状态：一个是可以被打断的（TASK_INTERRUPTIBLE），我 们用 ps 查看到的进程，显示为 S stat。还有一个是不可被打断的（TASK_UNINTERRUPTIBLE），用 ps 查看进程，就显示为 D stat。

除了上面进程在活的时候的两个状态，进程在调用 do_exit() 退出的时候，还有两个状态。 

一个是 EXIT_DEAD，也就是进程在真正结束退出的那一瞬间的状态；第二个是 EXIT_ZOMBIE 状态，这是进程在 EXIT_DEAD 前的一个状态，而我们今天讨论的僵尸进 程，也就是处于这个状态中。

## 僵尸进程
![[Pasted image 20220826165504.png]]
一个正常的进程退出流程是这样的：

-   子进程退出后，给父进程发送一个SIGCHLD的信号
-   父进程收到这个信号后，会通过wait系统调用来回收子进程

1. 僵尸进程产生原因：

僵尸进程是当子进程比父进程先结束，而父进程又没有回收子进程，释放子进程占用的资源，此时子进程将成为一个僵尸进程。如果父进程先退出 ，子进程被init接管，子进程退出后init会回收其占用的相关资源

当一个进程创建了一个子进程时，他们的运行是异步的。即父进程无法预知子进程会在什么时候结束，那么如果父进程很繁忙来不及wait 子进程时，那么当子进程结束时，会丢失子进程的结束时的状态信息，处于这种考虑unix提供了一种机制可以保证只要父进程想知道子进程结束时的信息，它就可以得到。

 这种机制是：在每个进程退出的时候，内核释放该进程所有的资源，包括打开的文件，占用的内存。但是仍然保留了一些信息，留下一个称为僵尸进程（Zombie）的数据结构（如进程号pid 退出状态 运行时间等）。这些保留的信息直到进程通过调用wait/waitpid时才会释放。这样就导致了一个问题，如果没有调用wait/waitpid的话，那么保留的信息就不会释放。

**“僵死状态”，指的是子进程退出后，在父进程使用wait对它进行回收之前的状态**。

2. 进程结束后为什么要进入僵尸状态?

因为父进程可能需要子进程的退出状态等信息。

3. 僵尸进程是每个子进程必经的状态吗？

是的。 任何一个子进程（init除外）在exit（）之后，并非马上就消失掉，而是留下一个称为僵尸进程（Zombie）的数据结构，等待父进程处理。这是每个子进程在结束时都要经过的阶段。如果子进程在exit（）之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。

## CPU使用率
![[Pasted image 20220826212543.png|800]]

假设一个用户程序开始运行了，那么就对应着第一个"us"框，"us"是"user"的缩写，代表Linux 的用户态 CPU Usage。普通用户程序代码中，只要不是调用系统调用（System Call），这些代码的指令消耗的 CPU 就都属于"us"。

当这个用户程序代码中调用了系统调用，比如说 read() 去读取一个文件，这时候这个用户进程就会从用户态切换到内核态。

内核态 read() 系统调用在读到真正 disk 上的文件前，就会进行一些文件系统层的操作。那么这些代码指令的消耗就属于"sy"，这里就对应上面图里的第二个框。"sy"是"system"的缩写，代表内核态 CPU 使用。

接下来，这个 read() 系统调用会向 Linux 的 Block Layer 发出一个 I/O Request，触发一个真正的磁盘读取操作。

这时候，这个进程一般会被置为 TASK_UNINTERRUPTIBLE。而 Linux 会把这段时间标示 成"wa"，对应图中的第三个框。"wa"是"iowait"的缩写，代表等待 I/O 的时间，这里的I/O 是指 Disk I/O。

紧接着，当磁盘返回数据时，进程在内核态拿到数据，这里仍旧是内核态的 CPU 使用中 的"sy"，也就是图中的第四个框。

然后，进程再从内核态切换回用户态，在用户态得到文件数据，这里进程又回到用户态的 CPU 使用，"us"，对应图中第五个框。

好，这里我们假设一下，这个用户进程在读取数据之后，没事可做就休眠了。并且我们可 以进一步假设，这时在这个 CPU 上也没有其他需要运行的进程了，那么系统就会进入"id"这个步骤，也就是第六个框。"id"是"idle"的缩写，代表系统处于空闲状态。

如果这时这台机器在网络收到一个网络数据包，网卡就会发出一个中断（interrupt）。相 应地，CPU 会响应中断，然后进入中断服务程序。

这时，CPU 就会进入"hi"，也就是第七个框。"hi"是"hardware irq"的缩写，代表 CPU 处 理硬中断的开销。由于我们的中断服务处理需要关闭中断，所以这个硬中断的时间不能太长。

但是，发生中断后的工作是必须要完成的，如果这些工作比较耗时那怎么办呢？Linux 中有 一个软中断的概念（softirq），它可以完成这些耗时比较长的工作。

你可以这样理解这个软中断，从网卡收到数据包的大部分工作，都是通过软中断来处理 的。那么，CPU 就会进入到第八个框，"si"。这里"si"是"softirq"的缩写，代表 CPU 处理 软中断的开销

一个是"ni"，是"nice"的缩写，这里表示如果进程的 nice 值是正值（1-19），代表优先级 比较低的进程运行时所占用的 CPU。

另外一个是"st"，"st"是"steal"的缩写，是在虚拟机里用的一个 CPU 使用类型，表示有多 少时间是被同一个宿主机上的其他虚拟机抢走的。
![[Pasted image 20220826212942.png|800]]

## top命令中的load average   VS   CPU Usage
第一，不论计算机 CPU 是空闲还是满负载，Load Average 都是 Linux 进程调度器中可运 行队列（Running Queue）里的一段时间的平均进程数目。

第二，计算机上的 CPU 还有空闲的情况下，CPU Usage 可以直接反映到"load average"上，什么是 CPU 还有空闲呢？具体来说就是可运行队列中的进程数目小于 CPU 个数，这种情况下，单位时间进程 CPU Usage 相加的平均值应该就是"load average"的 值。

第三，计算机上的 CPU 满负载的情况下，计算机上的 CPU 已经是满负载了，同时还有更 多的进程在排队需要 CPU 资源。这时"load average"就不能和 CPU Usage 等同了。

平均负载load average统计了这两种情况的进程：
第一种是 Linux 进程调度器中可运行队列（Running Queue）一段时间（1 分钟，5 分 钟，15 分钟）的进程平均数。
第二种是 Linux 进程调度器中休眠队列（Sleeping Queue）里的一段时间的 TASK_UNINTERRUPTIBLE 状态下的进程平均数。

所以，最后的公式就是：Load Average= 可运行队列进程平均数 + 休眠队列中不可打断的进程平均数
![[Pasted image 20220826221705.png|700]]
在其他 Unix 操作系统里 Load Average 只考虑 CPU 部分，Load Average 计算的是进程 调度器中可运行队列（Running Queue）里的一段时间（1 分钟，5 分钟，15 分钟）的平 均进程数目，而 Linux 在这个基础上，又加上了进程调度器中休眠队列（Sleeping Queue）里的一段时间的 TASK_UNINTERRUPTIBLE 状态的平均进程数目。

## 并发操作中，linux解决数据同步的四种方法
#### 1.原子变量
在只有单个变量全局数据的情况下，这种变量非常实用，如全局计数器、状 态标志变量等。我们利用了 CPU 的原子指令实现了一组操作原子变量的函数。 

#### 2.中断的控制
当要操作的数据很多的情况下，用原子变量就不适合了。但是我们发现在 单核心的 CPU，同一时刻只有一个代码执行流，除了响应中断导致代码执行流切换，不会 有其它条件会干扰全局数据的操作，所以我们只要在操作全局数据时关闭或者开启中断就 行了，为此我们开发了控制中断的函数。 

中断是 CPU 响应外部事件的重要机制，时钟、键盘、硬盘等 IO 设备都是通过发出中断来 请求 CPU 执行相关操作的（即执行相应的中断处理代码），比如下一个时钟到来、用户按 下了键盘上的某个按键、硬盘已经准备好了数据。

#### 3.自旋锁
由于多核心的 CPU 出现，控制中断已经失效了，因为系统中同时有多个代码执 行流，为了解决这个问题，我们开发了自旋锁，自旋锁要么一下子获取锁，要么循环等待 最终获取锁。 

首先读取锁变量，判断其值是否已经加锁，如果 未加锁则执行加锁，然后返回，表示加锁成功；如果已经加锁了，就要返回第一步继续执 行后续步骤，因而得名自旋锁。

![[Pasted image 20220901091240.png|400]]
linux有多种自旋锁，例如原始自旋锁和排队自旋锁等

#### 4.信号量
如果长时间等待后才能获取数据，在这样的情况下，前面中断控制和自旋锁都 不能很好地解决，于是我们开发了信号量。信号量由一套数据结构和函数组成，它能使获 取数据的代码执行流进入睡眠，然后在相关条件满足时被唤醒，这样就能让 CPU 能有时间 处理其它任务。所以信号量同时解决了三个问题：等待、互斥、唤醒。

Linux 中的信号量同样是用来保护共享资源，能保证资源在一个时刻只有一个进程使用，这 是单值信号量。也可以作为资源计数器，比如一种资源有五份，同时最多可以有五个进 程，这是多值信号量。

单值信号量，类比于私人空间一次只进去一个人，其信号量的值初始值为 1，而多值信号量，相当于是客厅，可同时容纳多个人。其信号量的值初始值为 5，就可容纳 5 个人。 

信号量的值为正的时候。所申请的进程可以锁定使用它。若为 0，说明它被其它进程占 用，申请的进程要进入睡眠队列中，等待被唤醒。所以信号量最大的优势是既可以使申请 失败的进程睡眠，还可以作为资源计数器使用。

#### 5.读写锁
在操作系统中，有很多共享数据，进程对这些共享数据要进行修改的情况很少，而读取的 情况却是非常多的，这些共享数据的操作基本都是在读取。 

如果每次读取这些共享数据都加锁的话，那就太浪费时间了，会降低进程的运行效率。因 为读操作不会导致修改数据，所以在读取数据的时候不用加锁了，而是可以共享的访问， 只有涉及到对共享数据修改的时候，才需要加锁互斥访问。 

想像一下 100 个进程同时读取一个共享数据，而每个进程都要加锁解锁，剩下的进程只能 等待，这会大大降低整个系统性能，这时候就需要使用一种新的锁了——读写锁。 

读写锁也称为共享 - 独占（shared-exclusive）锁，当读写锁用读取模式加锁时，它是以 共享模式上锁的，当以写入修改模式加锁时，它是以独占模式上锁的（互斥）。 

读写锁非常适合读取数据的频率远大于修改数据的频率的场景中。这样可以在任何时刻， 保证多个进程的读取操作并发地执行，给系统带来了更高的并发度。 

那读写锁是怎么工作的呢？读写之间是互斥的，读取的时候不能写入，写入的时候不能读 取，而且读取和写入操作在竞争锁的时候，写会优先得到锁，步骤如下。 

1. 当共享数据没有锁的时候，读取的加锁操作和写入的加锁操作都可以满足。
2. 当共享数据有读锁的时候，所有的读取加锁操作都可以满足，写入的加锁操作不能满足，读写是互斥的。
3. 当共享数据有写锁的时候，所有的读取的加锁操作都不能满足，所有的写入的加锁操作 也不能满足，读与写之间是互斥的，写与写之间也是互斥的。

![[Pasted image 20220901094226.png|600]]

## VFS
在 Linux 中，支持 EXT、XFS、JFS、BTRFS、FAT、NTFS 等多达十几种不同的文件系 统，但不管在什么储存设备上使用什么文件系统，也不管访问什么文件，都可以统一地使 用一套 open(), read()、write()、close() 这样的接口。 

这些接口看上去都很简单，但要基于不同的存储设备设计，还要适应不同的文件系统，这 并不容易。这就得靠优秀的 VFS 了，它提供了一个抽象层，让不同的文件系统表现出一致 的行为。
![[Pasted image 20220905100444.png|600]]
上图中 Linux 的 VFS 层就是应用和许多文件系统之间的抽象层。VFS 向上对应用提供 了操作文件的标准接口，向下规范了一个文件系统要接入 VFS 必需要实现的机制。

## Page Cache
![[Pasted image 20220905151517.png|600]]
1. Page Cache 是属于内核的，不属于用户。 
2. Page Cache 对应用提升 I/O 效率而言是一个投入产出比较高的方案，所以它的存在还 是有必要的。

### Page Cache 是如何“诞生”的？
![[Pasted image 20220905152142.png|900]]
Page Cache 的产生有两种不同的方式：
**Buffered I/O（标准 I/O）：**
标准 I/O 是写的 (write(2)) 用户缓冲区 (Userpace Page 对应的内存)，然后再将用户缓冲区里的数据拷贝到内核缓冲区 (Pagecache Page 对应的内存)；如果是读的 (read(2)) 话则是先从内核缓冲区拷贝到用户缓冲区，再从用户缓冲区读数据，也就是 buffer 和文件内容 不存在任何映射关系。
![[Pasted image 20220905152650.png|800]]
这个过程大致可以描述为：首先往用户缓冲区 buffer(这是 Userspace Page) 写入数据， 然后 buffer 中的数据拷贝到内核缓冲区（这是 Pagecache Page），如果内核缓冲区中还 没有这个 Page，就会发生 Page Fault 会去分配一个 Page，拷贝结束后该 Pagecache Page 是一个 Dirty Page（脏页），然后该 Dirty Page 中的内容会同步到磁盘，同步到磁 盘后，该 Pagecache Page 变为 Clean Page 并且继续存在系统中。 

我建议你可以将 Alloc Page 理解为 Page Cache 的“诞生”，将 Dirty Page 理解为 Page Cache 的婴幼儿时期（最容易生病的时期），将 Clean Page 理解为 Page Cache 的成年时期（在这个时期就很少会生病了）。

但是请注意，并不是所有人都有童年的，比如孙悟空，一出生就是成人了，Page Cache 也一样，如果是读文件产生的 Page Cache，它的内容跟磁盘内容是一致的，所以它一开 始是 Clean Page，除非改写了里面的内容才会变成 Dirty Page（返老还童）。

**Memory-Mapped I/O（存储映射 I/O）：**
对于存储映射 I/O 而言，则是直接将 Pagecache Page 给映射到用户地址空间，用户直接读写 Pagecache Page 中内容。

显然，存储映射 I/O 要比标准 I/O 效率高一些，毕竟少了“用户空间到内核空间互相拷 贝”的过程。这也是很多应用开发者发现，为什么使用内存映射 I/O 比标准 I/O 方式性能 要好一些的主要原因。

### Page Cache 是如何“死亡”的？
你可以把 Page Cache 的回收行为 (Page Reclaim) 理解为 Page Cache 的“自然死 亡”。

free 命令中的 buff/cache 中的这些就是“活着”的 Page Cache，那它们什么时候会“死 亡”（被回收）呢？我们来看一张图：
![[Pasted image 20220905153331.png]]
你可以看到，应用在申请内存的时候，即使没有 free 内存，只要还有足够可回收的 Page Cache，就可以通过回收 Page Cache 的方式来申请到内存，回收的方式主要是两种：**直接回收和后台回收**

**直接内存**回收是在进程申请内存的过程中同步进行的回收，而这个回收过程可能会消 耗很多时间，进而导致进程的后续行为都被迫等待，这样就会造成很长时间的延迟，以及 系统的 CPU 利用率会升高，最终引起 load 飙高。
![[Pasted image 20220905153645.png|600]]
在开始内存回收后，首先进行后台异步回收（上图中蓝色标记的地 方），这不会引起进程的延迟；如果后台异步回收跟不上进行内存申请的速度，就会开始同步阻塞回收，导致延迟（上图中红色和粉色标记的地方，这就是引起 load 高的地址）。

针对直接内存回收引起 load 飙高或者业务 RT 抖动的问题，一个解决方案就是及早地触发后台回收来避免应用程序进行直接内存回收。

直接回收过程中，如果存在较多脏页就可能涉及在回收过程中进行回写，这可能会造成非常大的延迟，而且因为这个过程本身是阻塞式的，所以又可能进一步导致系统中处于 D 状态的进程数增多，最终的表现就是系统的 load 值很高。

### 如何避免 Page Cache 里相对比较重要的数据被回收掉：
避免 Page Cache 里相对比较重要的数据被回收掉的思路也是有两种：
**从应用代码层面来优化；** 
从应用程序代码层面来解决是相对比较彻底的方案，因为应用更清楚哪些 Page Cache 是 重要的，哪些是不重要的，所以就可以明确地来对读写文件过程中产生的 Page Cache 区 别对待。比如说，对于重要的数据，可以通过 mlock(2) 来保护它，防止被回收以及被 drop；对于不重要的数据（比如日志），那可以通过 madvise(2) 告诉内核来立即释放这 些 Page Cache。

**从系统层面来调整。**
在有些情况下，对应用程序而言，修改源码是件比较麻烦的事，如果可以不修改源码来达 到目的那就最好不过了。Linux 内核同样实现了这种不改应用程序的源码而从系统层面调整 来保护重要数据的机制，这个机制就是 **memory cgroup protection**
它大致的思路是，将需要保护的应用程序使用 memory cgroup 来保护起来，这样该应用 程序读写文件过程中所产生的 Page Cache 就会被保护起来不被回收或者最后被回收。 memory cgroup protection 大致的原理如下图所示：
![[Pasted image 20220905162909.png|600]]
如上图所示，memory cgroup 提供了几个内存水位控制线 memory.{min, low, high, max} 。
**memory.max**
这是指 memory cgroup 内的进程最多能够分配的内存，如果不设置的话，就默认不做 内存大小的限制。
**memory.high**
如果设置了这一项，当 memory cgroup 内进程的内存使用量超过了该值后就会立即被回收掉，所以这一项的目的是为了尽快的回收掉不活跃的 Page Cache。
**memory.low**
这一项是用来保护重要数据的，当 memory cgroup 内进程的内存使用量低于了该值后，在内存紧张触发回收后就会先去回收不属于该 memory cgroup 的 Page Cache， 等到其他的 Page Cache 都被回收掉后再来回收这些 Page Cache。
**memory.min**
这一项同样是用来保护重要数据的，只不过与 memoy.low 有所不同的是，当 memory cgroup 内进程的内存使用量低于该值后，即使其他不在该 memory cgroup 内的 Page Cache 都被回收完了也不会去回收这些 Page Cache，可以理解为这是用来保护 最高优先级的数据的。

那么，如果你想要保护你的 Page Cache 不被回收，你就可以考虑将你的业务进程放在一 个 memory cgroup 中，然后设置 memory.{min,low} 来进行保护；与之相反，如果你 想要尽快释放你的 Page Cache，那你可以考虑设置 memory.high 来及时的释放掉不活 跃的 Page Cache。

## 进程地址空间
我们用一张图，来表示进程的地址空间。图的左侧是说进程可以通过什么方式来更改进程 虚拟地址空间，而中间就是进程虚拟地址空间是如何划分的，右侧则是进程的虚拟地址空 间所对应的物理内存或者说物理地址空间。
![[Pasted image 20220905165136.png|700]]

应用程序都是跟虚拟地址打交道，不会直接跟物理地址 打交道。而虚拟地址最终都要转换为物理地址，由于 Linux 都是使用 Page（页）来进行管 理的，所以这个过程叫 Paging（分页）。

![[Pasted image 20220905165246.png|700]]
进程运行所需要的内存类型有很多种，总的来说，这些内存类型可以从是不是文件映射， 以及是不是私有内存这两个不同的维度来做区分，也就是可以划分为上面所列的四类内存。
**私有匿名内存**。进程的堆、栈，以及 mmap(MAP_ANON | MAP_PRIVATE) 这种方式 申请的内存都属于这种类型的内存。其中栈是由操作系统来进行管理的，应用程序无需 关注它的申请和释放；堆和私有匿名映射则是由应用程序（程序员）来进行管理的，它 们的申请和释放都是由应用程序来负责的，所以它们是容易产生内存泄漏的地方。 

**共享匿名内存**。进程通过 mmap(MAP_ANON | MAP_SHARED) 这种方式来申请的内 存，比如说 tmpfs 和 shm。这个类型的内存也是由应用程序来进行管理的，所以也可 能会发生内存泄漏。 

**私有文件映射**。进程通过 mmap(MAP_FILE | MAP_PRIVATE) 这种方式来申请的内存， 比如进程将共享库（Shared libraries）和可执行文件的代码段（Text Segment）映射到自己的地址空间就是通过这种方式。对于共享库和可执行文件的代码段的映射，这是 通过操作系统来进行管理的，应用程序无需关注它们的申请和释放。而应用程序直接通 过 mmap(MAP_FILE | MAP_PRIVATE) 来申请的内存则是需要应用程序自己来进行管 理，这也是可能会发生内存泄漏的地方。

**共享文件映射**。进程通过 mmap(MAP_FILE | MAP_SHARED) 这种方式来申请的内存， 我们在上一个模块课程中讲到的 File Page Cache 就属于这类内存。这部分内存也需要应用程序来申请和释放，所以也存在内存泄漏的可能性.


![[Pasted image 20220905165519.png|700]]
如上图所示，**Paging 的大致过程是**，CPU 将要请求的虚拟地址传给 MMU（Memory Management Unit，内存管理单元），然后 MMU 先在高速缓存 TLB（Translation Lookaside Buffer，页表缓存）中查找转换关系，如果找到了相应的物理地址则直接访 问；如果找不到则在地址转换表（Page Table）里查找计算。最终进程访问的虚拟地址就 对应到了实际的物理地址。

#### 进程内存管理
进程直接读写的都是虚拟地址，虚拟地址最终会通过 Paging（分页）来转换为物理内存 的地址，Paging 这个过程是由内核来完成的。

进程的内存类型可以从 anon（匿名）与 file（文件）、private（私有）与 shared（共 享）这四项来区分为 4 种不同的类型，进程相关的所有内存都是这几种方式的不同组 合。

查看进程内存时，可以先使用 top 来看系统中各个进程的内存使用概况，再使用 pmap 去观察某个进程的内存细节。
![[Pasted image 20220905210037.png|800]]

### tmpfs
我们知道，磁盘的速度是远远低于内存的，有些应用程序为了提升性能，会避免将一些无需持续化存储的数据写入到磁盘，而是把这部分临时数据写入到内存中，然后定期或者在不需要这部分数据时，清理掉这部分内容来释放出内存。在这种需求下，就产生了一种特殊的 Shmem：tmpfs。tmpfs 如下图所示：
![[Pasted image 20220905212758.png|700]]
它是一种内存文件系统，只存在于内存中，它无需应用程序去申请和释放内存，而是操作 系统自动来规划好一部分空间，应用程序只需要往这里面写入数据就可以了，这样会很方 便。我们可以使用 moun 命令或者 df 命令来看系统中 tmpfs 的挂载点。

很多应用程序会把日志保存在tmpfs里，也有些应用会把它的运行时文件保存在tmpfs里。比如systemd就会把日志记录到tmpfs中。你可以用mount命令来查看你的系统tmpfs挂载 路径，然后去这里面查看有哪些文件，你也可以看出来你的系统里有哪些应用会用到tmpfs.

## 进程的虚拟地址空间
进程的虚拟地址空间（address space）既包括用户地址空 间，也包括内核地址空间。这可以简单地理解为，进程运行在用户态申请的内存，对应的 是用户地址空间，进程运行在内核态申请的内存，对应的是内核地址空间，如下图所示：
![[Pasted image 20220905214125.png|900]]
应用程序可以通过 malloc() 和 free() 在用户态申请和释放内存，与之对应，可以通过 kmalloc()/kfree() 以及 vmalloc()/vfree() 在内核态申请和释放内存。当然，还有其他申请 和释放内存的方法，但大致可以分为这两类。

从最右侧的物理内存中你可以看出这两类内存申请方式的主要区别，kmalloc() 内存的物理 地址是连续的，而 vmalloc() 内存的物理地址则是不连续的。这两种不同类型的内存也是 可以通过 /proc/meminfo 来观察的。

其中 vmalloc 申请的内存会体现在 VmallocUsed 这一项中，即已使用的 Vmalloc 区大 小；而 kmalloc 申请的内存则是体现在 Slab 这一项中，它又分为两部分，其中 SReclaimable 是指在内存紧张的时候可以被回收的内存，而 SUnreclaim 则是不可以被回 收只能主动释放的内存。